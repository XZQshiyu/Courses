{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import datasets, models, transforms\n",
    "from torchvision.transforms import ToTensor, Resize, Compose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training components"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./components.png\" width=\"80%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, img_dir, transform=None, target_transform=None):  \n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        # load the files \n",
    "        filenames = []\n",
    "        labels = []\n",
    "        for filename in os.listdir(img_dir):\n",
    "            filenames.append(filename)\n",
    "            if filename.startswith(\"bird\"):\n",
    "                labels.append(0)\n",
    "            elif filename.startswith(\"cat\"):\n",
    "                labels.append(1)\n",
    "            elif filename.startswith(\"dog\"):\n",
    "                labels.append(2)\n",
    "        self.filenames = filenames\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.filenames[idx])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pet_dataset = CustomImageDataset(\"./data/pets\",transform = Compose([ToTensor(), Resize((28,28))]))\n",
    "train_size = int(0.8 * len(pet_dataset))\n",
    "test_size = len(pet_dataset) - train_size\n",
    "\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(pet_dataset, [train_size, test_size])\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=6, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Models\n",
    "Here we try two different neural networks: \n",
    "- Simple model with some convolutional layers;\n",
    "- A pretrained classical convolutional neural network architecture: ResNet18."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "ConvNN(\n",
      "  (conv_stack): Sequential(\n",
      "    (0): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (1): ReLU()\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
      "    (4): ReLU()\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): Flatten(start_dim=1, end_dim=-1)\n",
      "    (7): ReLU()\n",
      "    (8): Linear(in_features=192, out_features=512, bias=True)\n",
      "    (9): ReLU()\n",
      "    (10): Linear(in_features=512, out_features=3, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "    \n",
    "# Define model\n",
    "class ConvNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNN, self).__init__()\n",
    "        self.conv_stack = nn.Sequential(\n",
    "            nn.Conv2d(3,6,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(6,12,5),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(192, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 3)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        logits = self.conv_stack(x)\n",
    "        return logits\n",
    "    \n",
    "\n",
    "conv_model = ConvNN().to(device)\n",
    "print(conv_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 224. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\23133\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\23133\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to C:\\Users\\23133/.cache\\torch\\hub\\checkpoints\\resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:02<00:00, 16.6MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define model, dataset and dataloader for vgg model\n",
    "\n",
    "resnet_model = models.resnet18(pretrained=True).to(device)\n",
    "resnet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_transform = Compose([ToTensor(), Resize((224,224)), transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                 std=[0.229, 0.224, 0.225])])\n",
    "\n",
    "pet_dataset_resnet = CustomImageDataset(\"./data/pets\",transform = resnet_transform)\n",
    "train_size = int(0.8 * len(pet_dataset_resnet))\n",
    "test_size = len(pet_dataset_resnet) - train_size\n",
    "\n",
    "train_dataset_resnet, test_dataset_resnet = torch.utils.data.random_split(pet_dataset_resnet, [train_size, test_size])\n",
    "\n",
    "train_dataloader_resnet = DataLoader(train_dataset_resnet, batch_size=6, shuffle=True)\n",
    "test_dataloader_resnet = DataLoader(test_dataset_resnet, batch_size=6, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "num_ftrs = resnet_model.fc.in_features\n",
    "print(num_ftrs)\n",
    "resnet_model.fc = nn.Linear(num_ftrs, 3)\n",
    "resnet_model = resnet_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing the Model Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To train a model, we need a `loss function` and an `optimizer`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = resnet_model\n",
    "trainloader = train_dataloader_resnet\n",
    "testloader = test_dataloader_resnet\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a single training loop, the model makes predictions on the training dataset (fed to it in batches), and\n",
    "backpropagates the prediction error to adjust the model's parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.train()\n",
    "    correct, train_loss = 0, 0 \n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        train_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()  \n",
    "        loss.backward()\n",
    "        optimizer.step() \n",
    "    correct /= size\n",
    "    train_loss /= num_batches\n",
    "    return train_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also check the model's performance against the test dataset to ensure it is learning.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval() \n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    return test_loss, correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The training process is conducted over several iterations (*epochs*). During each epoch, the model learns\n",
    "parameters to make better predictions. We print the model's accuracy and loss at each epoch; we'd like to see the\n",
    "accuracy increase and the loss decrease with every epoch.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:\n",
      "Train Error. Accuracy: 70.8%, Avg loss: 0.681271\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.197678\n",
      "Epoch 1:\n",
      "Train Error. Accuracy: 87.5%, Avg loss: 0.367318\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.386519\n",
      "Epoch 2:\n",
      "Train Error. Accuracy: 90.6%, Avg loss: 0.212756\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.128781\n",
      "Epoch 3:\n",
      "Train Error. Accuracy: 96.9%, Avg loss: 0.092067\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.234279\n",
      "Epoch 4:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.082397\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.244073\n",
      "Epoch 5:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.045263\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.139338\n",
      "Epoch 6:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.047985\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.065401\n",
      "Epoch 7:\n",
      "Train Error. Accuracy: 95.8%, Avg loss: 0.106709\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.252171\n",
      "Epoch 8:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.070981\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.182017\n",
      "Epoch 9:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.030131\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.202738\n",
      "Epoch 10:\n",
      "Train Error. Accuracy: 90.6%, Avg loss: 0.243902\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.206274\n",
      "Epoch 11:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.061798\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.105727\n",
      "Epoch 12:\n",
      "Train Error. Accuracy: 96.9%, Avg loss: 0.132859\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.141775\n",
      "Epoch 13:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.078032\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.188122\n",
      "Epoch 14:\n",
      "Train Error. Accuracy: 96.9%, Avg loss: 0.131119\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.148182\n",
      "Epoch 15:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.016877\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.136058\n",
      "Epoch 16:\n",
      "Train Error. Accuracy: 92.7%, Avg loss: 0.187670\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.211521\n",
      "Epoch 17:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.038356\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.150485\n",
      "Epoch 18:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.013634\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.148011\n",
      "Epoch 19:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.014898\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.141536\n",
      "Epoch 20:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.033182\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.153970\n",
      "Epoch 21:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.022578\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.121404\n",
      "Epoch 22:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.009437\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.138295\n",
      "Epoch 23:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.019152\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.136159\n",
      "Epoch 24:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.039742\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.191810\n",
      "Epoch 25:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.011623\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.122366\n",
      "Epoch 26:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.009522\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.114777\n",
      "Epoch 27:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.017492\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.111283\n",
      "Epoch 28:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.018522\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.152791\n",
      "Epoch 29:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.033888\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.248422\n",
      "Epoch 30:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.010712\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.175333\n",
      "Epoch 31:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.019207\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.128491\n",
      "Epoch 32:\n",
      "Train Error. Accuracy: 96.9%, Avg loss: 0.065536\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.331318\n",
      "Epoch 33:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.037013\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.196144\n",
      "Epoch 34:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.031932\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.182342\n",
      "Epoch 35:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.031359\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.419372\n",
      "Epoch 36:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.012803\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.361500\n",
      "Epoch 37:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.008358\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.360246\n",
      "Epoch 38:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.018633\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.437179\n",
      "Epoch 39:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.016417\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.428569\n",
      "Epoch 40:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004368\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.390635\n",
      "Epoch 41:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.012022\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.418195\n",
      "Epoch 42:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007114\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.312453\n",
      "Epoch 43:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.012886\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.363830\n",
      "Epoch 44:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.006452\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.376000\n",
      "Epoch 45:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.011034\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.390507\n",
      "Epoch 46:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005675\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.425418\n",
      "Epoch 47:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001333\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.398016\n",
      "Epoch 48:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.006404\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.337385\n",
      "Epoch 49:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002934\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.346173\n",
      "Epoch 50:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.008446\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.282386\n",
      "Epoch 51:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003301\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.238340\n",
      "Epoch 52:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002092\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.207193\n",
      "Epoch 53:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005919\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.175415\n",
      "Epoch 54:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002858\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.161771\n",
      "Epoch 55:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003205\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.175475\n",
      "Epoch 56:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000882\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.183349\n",
      "Epoch 57:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002433\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.189761\n",
      "Epoch 58:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004957\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.165239\n",
      "Epoch 59:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004714\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.548102\n",
      "Epoch 60:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007854\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.244679\n",
      "Epoch 61:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.036588\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.486242\n",
      "Epoch 62:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.022904\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.475964\n",
      "Epoch 63:\n",
      "Train Error. Accuracy: 94.8%, Avg loss: 0.299689\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.154832\n",
      "Epoch 64:\n",
      "Train Error. Accuracy: 94.8%, Avg loss: 0.123707\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.035975\n",
      "Epoch 65:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.029408\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.062597\n",
      "Epoch 66:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007680\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.067863\n",
      "Epoch 67:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.009151\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.096079\n",
      "Epoch 68:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005320\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.074828\n",
      "Epoch 69:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004560\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.048936\n",
      "Epoch 70:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005891\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.067682\n",
      "Epoch 71:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001775\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.065007\n",
      "Epoch 72:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.006156\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.066965\n",
      "Epoch 73:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000585\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.080068\n",
      "Epoch 74:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007413\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.071610\n",
      "Epoch 75:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004289\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.097665\n",
      "Epoch 76:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003968\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.151336\n",
      "Epoch 77:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001670\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.116029\n",
      "Epoch 78:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.039171\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.086795\n",
      "Epoch 79:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005855\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.125582\n",
      "Epoch 80:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002475\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.145940\n",
      "Epoch 81:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001091\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.131393\n",
      "Epoch 82:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002881\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.174031\n",
      "Epoch 83:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003888\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.159917\n",
      "Epoch 84:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001069\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.140145\n",
      "Epoch 85:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000616\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.094637\n",
      "Epoch 86:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005478\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.078969\n",
      "Epoch 87:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002357\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.076352\n",
      "Epoch 88:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000923\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.071859\n",
      "Epoch 89:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000786\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.076894\n",
      "Epoch 90:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002793\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.056376\n",
      "Epoch 91:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000712\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.074080\n",
      "Epoch 92:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000592\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.057385\n",
      "Epoch 93:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001118\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.063274\n",
      "Epoch 94:\n",
      "Train Error. Accuracy: 94.8%, Avg loss: 0.252311\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.104153\n",
      "Epoch 95:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.075377\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.148161\n",
      "Epoch 96:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.011028\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.093115\n",
      "Epoch 97:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.065528\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.125636\n",
      "Epoch 98:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.030173\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.159654\n",
      "Epoch 99:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005574\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.184196\n",
      "Epoch 100:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004277\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.146817\n",
      "Epoch 101:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002564\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.126686\n",
      "Epoch 102:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005683\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.130713\n",
      "Epoch 103:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005042\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.130102\n",
      "Epoch 104:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000966\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.122228\n",
      "Epoch 105:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003643\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.147976\n",
      "Epoch 106:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001088\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.154020\n",
      "Epoch 107:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001821\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.173885\n",
      "Epoch 108:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001726\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.137831\n",
      "Epoch 109:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000641\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.140159\n",
      "Epoch 110:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001884\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.177876\n",
      "Epoch 111:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001384\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.145938\n",
      "Epoch 112:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000800\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.183972\n",
      "Epoch 113:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000247\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.123759\n",
      "Epoch 114:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000453\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.118151\n",
      "Epoch 115:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001121\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.106152\n",
      "Epoch 116:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001184\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.117431\n",
      "Epoch 117:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000818\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.112581\n",
      "Epoch 118:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.053269\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.564303\n",
      "Epoch 119:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.029405\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.514460\n",
      "Epoch 120:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.009526\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.614230\n",
      "Epoch 121:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.011280\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.639425\n",
      "Epoch 122:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003702\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.567533\n",
      "Epoch 123:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001985\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.427771\n",
      "Epoch 124:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001649\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.405376\n",
      "Epoch 125:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001019\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.514887\n",
      "Epoch 126:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001295\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.526607\n",
      "Epoch 127:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001096\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.424068\n",
      "Epoch 128:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000973\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.532397\n",
      "Epoch 129:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000668\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.512499\n",
      "Epoch 130:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000616\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.468162\n",
      "Epoch 131:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000682\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.376393\n",
      "Epoch 132:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000340\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.428154\n",
      "Epoch 133:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001032\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.338448\n",
      "Epoch 134:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000775\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.330478\n",
      "Epoch 135:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000329\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.285921\n",
      "Epoch 136:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000430\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.283871\n",
      "Epoch 137:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000503\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.284454\n",
      "Epoch 138:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001037\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.340021\n",
      "Epoch 139:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001108\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.295281\n",
      "Epoch 140:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000412\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.273925\n",
      "Epoch 141:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000212\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.233918\n",
      "Epoch 142:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000353\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.263954\n",
      "Epoch 143:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000817\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.215419\n",
      "Epoch 144:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000165\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.269084\n",
      "Epoch 145:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000442\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.220132\n",
      "Epoch 146:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000229\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.235836\n",
      "Epoch 147:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000148\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.249814\n",
      "Epoch 148:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000099\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.267549\n",
      "Epoch 149:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000093\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.231769\n",
      "Epoch 150:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000130\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.269878\n",
      "Epoch 151:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000266\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.197729\n",
      "Epoch 152:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000761\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.229490\n",
      "Epoch 153:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000631\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.349561\n",
      "Epoch 154:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.085994\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.542098\n",
      "Epoch 155:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.084451\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.700124\n",
      "Epoch 156:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.025895\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.720380\n",
      "Epoch 157:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.014591\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.613264\n",
      "Epoch 158:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001875\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.443546\n",
      "Epoch 159:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000793\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.416219\n",
      "Epoch 160:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000937\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.387064\n",
      "Epoch 161:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002058\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.354452\n",
      "Epoch 162:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001310\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.362056\n",
      "Epoch 163:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000993\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.366863\n",
      "Epoch 164:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001869\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.325007\n",
      "Epoch 165:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000468\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.301860\n",
      "Epoch 166:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.029881\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.377076\n",
      "Epoch 167:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001513\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.518384\n",
      "Epoch 168:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003534\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.541669\n",
      "Epoch 169:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.012862\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.631663\n",
      "Epoch 170:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.020282\n",
      "Test Error. Accuracy: 70.8%, Avg loss: 0.813107\n",
      "Epoch 171:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.006664\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.622024\n",
      "Epoch 172:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004321\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.778798\n",
      "Epoch 173:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003283\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.441436\n",
      "Epoch 174:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001349\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.265255\n",
      "Epoch 175:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000884\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.310384\n",
      "Epoch 176:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.093666\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.360383\n",
      "Epoch 177:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.063250\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.379335\n",
      "Epoch 178:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002924\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.256172\n",
      "Epoch 179:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001582\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.232510\n",
      "Epoch 180:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001492\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.240297\n",
      "Epoch 181:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002291\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.205463\n",
      "Epoch 182:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001562\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.247282\n",
      "Epoch 183:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001051\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.186307\n",
      "Epoch 184:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002041\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.177154\n",
      "Epoch 185:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002146\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.205485\n",
      "Epoch 186:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002046\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.296601\n",
      "Epoch 187:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000825\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.253941\n",
      "Epoch 188:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000795\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.215459\n",
      "Epoch 189:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000356\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.234729\n",
      "Epoch 190:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000842\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.216104\n",
      "Epoch 191:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000720\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.219755\n",
      "Epoch 192:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000536\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.210765\n",
      "Epoch 193:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000398\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.205592\n",
      "Epoch 194:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000368\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.202181\n",
      "Epoch 195:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001339\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.274770\n",
      "Epoch 196:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000669\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.262757\n",
      "Epoch 197:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000349\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.271938\n",
      "Epoch 198:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000795\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.274152\n",
      "Epoch 199:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000356\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.242854\n",
      "Epoch 200:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000385\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.295155\n",
      "Epoch 201:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000466\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.326447\n",
      "Epoch 202:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000895\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.272962\n",
      "Epoch 203:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000250\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.225817\n",
      "Epoch 204:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000157\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.243188\n",
      "Epoch 205:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000260\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.236428\n",
      "Epoch 206:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000180\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.236812\n",
      "Epoch 207:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000168\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.224146\n",
      "Epoch 208:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000311\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.245919\n",
      "Epoch 209:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000153\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.207280\n",
      "Epoch 210:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000167\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.285526\n",
      "Epoch 211:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000130\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.272560\n",
      "Epoch 212:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000104\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.252280\n",
      "Epoch 213:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000226\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.252368\n",
      "Epoch 214:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000091\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.243877\n",
      "Epoch 215:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000279\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.272167\n",
      "Epoch 216:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000180\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.233428\n",
      "Epoch 217:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000117\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.232140\n",
      "Epoch 218:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000212\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.288577\n",
      "Epoch 219:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000073\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.258984\n",
      "Epoch 220:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000253\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.195331\n",
      "Epoch 221:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000268\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.227547\n",
      "Epoch 222:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000250\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.154307\n",
      "Epoch 223:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000098\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.118235\n",
      "Epoch 224:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000341\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.132229\n",
      "Epoch 225:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000340\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.086388\n",
      "Epoch 226:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000399\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.148052\n",
      "Epoch 227:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000311\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.208076\n",
      "Epoch 228:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000882\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.244848\n",
      "Epoch 229:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.008322\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.167397\n",
      "Epoch 230:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.020467\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.403524\n",
      "Epoch 231:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.135676\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.498564\n",
      "Epoch 232:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004037\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.067261\n",
      "Epoch 233:\n",
      "Train Error. Accuracy: 96.9%, Avg loss: 0.300074\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.315857\n",
      "Epoch 234:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.057984\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.107463\n",
      "Epoch 235:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003497\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.089145\n",
      "Epoch 236:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001674\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.104778\n",
      "Epoch 237:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.029084\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.365972\n",
      "Epoch 238:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.040341\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.109694\n",
      "Epoch 239:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001803\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.089682\n",
      "Epoch 240:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001243\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.082954\n",
      "Epoch 241:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001607\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.077827\n",
      "Epoch 242:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000443\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.086536\n",
      "Epoch 243:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001774\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.092543\n",
      "Epoch 244:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.024325\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.196562\n",
      "Epoch 245:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001700\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.318496\n",
      "Epoch 246:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005829\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.239946\n",
      "Epoch 247:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004279\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.187226\n",
      "Epoch 248:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000547\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.154343\n",
      "Epoch 249:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000280\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.139096\n",
      "Epoch 250:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000421\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.137190\n",
      "Epoch 251:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000491\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.142109\n",
      "Epoch 252:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000461\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.151231\n",
      "Epoch 253:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000980\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.176609\n",
      "Epoch 254:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000676\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.177476\n",
      "Epoch 255:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000296\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.168858\n",
      "Epoch 256:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000161\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.164821\n",
      "Epoch 257:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000223\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.144502\n",
      "Epoch 258:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000371\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.159766\n",
      "Epoch 259:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000235\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.169065\n",
      "Epoch 260:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000227\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.171604\n",
      "Epoch 261:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000817\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.374862\n",
      "Epoch 262:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.036805\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.540925\n",
      "Epoch 263:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.081354\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.097726\n",
      "Epoch 264:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002675\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.385440\n",
      "Epoch 265:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002059\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.440516\n",
      "Epoch 266:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000608\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.469249\n",
      "Epoch 267:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002021\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.474263\n",
      "Epoch 268:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001873\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.278631\n",
      "Epoch 269:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000451\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.349746\n",
      "Epoch 270:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000213\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.299895\n",
      "Epoch 271:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000502\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.329854\n",
      "Epoch 272:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001207\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.334517\n",
      "Epoch 273:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000146\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.316948\n",
      "Epoch 274:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000336\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.351814\n",
      "Epoch 275:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000264\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.388725\n",
      "Epoch 276:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000128\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.377460\n",
      "Epoch 277:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000139\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.359573\n",
      "Epoch 278:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000192\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.355765\n",
      "Epoch 279:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000137\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.308597\n",
      "Epoch 280:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000191\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.268616\n",
      "Epoch 281:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000199\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.285953\n",
      "Epoch 282:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000093\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.298406\n",
      "Epoch 283:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000400\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.270382\n",
      "Epoch 284:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000141\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.265402\n",
      "Epoch 285:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000221\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.321141\n",
      "Epoch 286:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000400\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.283100\n",
      "Epoch 287:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000093\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.289355\n",
      "Epoch 288:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000150\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.239352\n",
      "Epoch 289:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000147\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.198032\n",
      "Epoch 290:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000076\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.271906\n",
      "Epoch 291:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000122\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.296549\n",
      "Epoch 292:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000105\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.305431\n",
      "Epoch 293:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000088\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.309477\n",
      "Epoch 294:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000064\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.270937\n",
      "Epoch 295:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000114\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.220003\n",
      "Epoch 296:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000194\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.182615\n",
      "Epoch 297:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000061\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.207150\n",
      "Epoch 298:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000051\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.230259\n",
      "Epoch 299:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.029395\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.588088\n",
      "Epoch 300:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.008185\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.823515\n",
      "Epoch 301:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001460\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 1.039487\n",
      "Epoch 302:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000490\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.938816\n",
      "Epoch 303:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000200\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.864545\n",
      "Epoch 304:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007129\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.766918\n",
      "Epoch 305:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.004215\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.832657\n",
      "Epoch 306:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000921\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.822652\n",
      "Epoch 307:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001622\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.745295\n",
      "Epoch 308:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.010709\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.780041\n",
      "Epoch 309:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001580\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.655361\n",
      "Epoch 310:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.010132\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.101544\n",
      "Epoch 311:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003806\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.273508\n",
      "Epoch 312:\n",
      "Train Error. Accuracy: 96.9%, Avg loss: 0.450674\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.651662\n",
      "Epoch 313:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.048259\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.719745\n",
      "Epoch 314:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001199\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.953770\n",
      "Epoch 315:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001593\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.973242\n",
      "Epoch 316:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.025342\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 1.520163\n",
      "Epoch 317:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007019\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.950464\n",
      "Epoch 318:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000483\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.845565\n",
      "Epoch 319:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001008\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.849717\n",
      "Epoch 320:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000716\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.787725\n",
      "Epoch 321:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001054\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.716219\n",
      "Epoch 322:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001089\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.741425\n",
      "Epoch 323:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000369\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.855048\n",
      "Epoch 324:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000316\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.753063\n",
      "Epoch 325:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001014\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.752953\n",
      "Epoch 326:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000333\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.747924\n",
      "Epoch 327:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000117\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.762267\n",
      "Epoch 328:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.073869\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.801297\n",
      "Epoch 329:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.005864\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 1.073178\n",
      "Epoch 330:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.033345\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.543801\n",
      "Epoch 331:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000969\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.699492\n",
      "Epoch 332:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002377\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.703654\n",
      "Epoch 333:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000926\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.612578\n",
      "Epoch 334:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000388\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.678164\n",
      "Epoch 335:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000965\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.575191\n",
      "Epoch 336:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000572\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.647452\n",
      "Epoch 337:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000411\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.633270\n",
      "Epoch 338:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000560\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.545771\n",
      "Epoch 339:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000278\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.572551\n",
      "Epoch 340:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000731\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.546177\n",
      "Epoch 341:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000167\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.665177\n",
      "Epoch 342:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000458\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.571909\n",
      "Epoch 343:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000634\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.608566\n",
      "Epoch 344:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000133\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.572442\n",
      "Epoch 345:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000191\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.559497\n",
      "Epoch 346:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000282\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.535025\n",
      "Epoch 347:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000249\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.631053\n",
      "Epoch 348:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000303\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.570756\n",
      "Epoch 349:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000147\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.602591\n",
      "Epoch 350:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000086\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.607952\n",
      "Epoch 351:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000131\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.593389\n",
      "Epoch 352:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000256\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.551000\n",
      "Epoch 353:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000202\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.551220\n",
      "Epoch 354:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000073\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.600854\n",
      "Epoch 355:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000106\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.509068\n",
      "Epoch 356:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000150\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.429657\n",
      "Epoch 357:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000130\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.486143\n",
      "Epoch 358:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000050\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.525124\n",
      "Epoch 359:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000044\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.515980\n",
      "Epoch 360:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000249\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.461911\n",
      "Epoch 361:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000083\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.517505\n",
      "Epoch 362:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000112\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.481029\n",
      "Epoch 363:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000850\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.436555\n",
      "Epoch 364:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000135\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.559012\n",
      "Epoch 365:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000162\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.572925\n",
      "Epoch 366:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000071\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.484690\n",
      "Epoch 367:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000067\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.463981\n",
      "Epoch 368:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000036\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.512514\n",
      "Epoch 369:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000276\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.444242\n",
      "Epoch 370:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000112\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.398332\n",
      "Epoch 371:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000050\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.407379\n",
      "Epoch 372:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000038\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.422840\n",
      "Epoch 373:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000057\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.422870\n",
      "Epoch 374:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000026\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.448884\n",
      "Epoch 375:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000318\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.588811\n",
      "Epoch 376:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000176\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.583884\n",
      "Epoch 377:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000164\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.444114\n",
      "Epoch 378:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.090698\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.543922\n",
      "Epoch 379:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000727\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.380144\n",
      "Epoch 380:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000118\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.312192\n",
      "Epoch 381:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.007146\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.205006\n",
      "Epoch 382:\n",
      "Train Error. Accuracy: 97.9%, Avg loss: 0.058072\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.409649\n",
      "Epoch 383:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.008942\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.540694\n",
      "Epoch 384:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002651\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.519044\n",
      "Epoch 385:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000402\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.548310\n",
      "Epoch 386:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000238\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.557582\n",
      "Epoch 387:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000427\n",
      "Test Error. Accuracy: 75.0%, Avg loss: 0.576389\n",
      "Epoch 388:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.054720\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.789123\n",
      "Epoch 389:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003372\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.718661\n",
      "Epoch 390:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001074\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.724424\n",
      "Epoch 391:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000811\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.677675\n",
      "Epoch 392:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000226\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.639678\n",
      "Epoch 393:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.045020\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.492864\n",
      "Epoch 394:\n",
      "Train Error. Accuracy: 99.0%, Avg loss: 0.021255\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.562795\n",
      "Epoch 395:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.002811\n",
      "Test Error. Accuracy: 79.2%, Avg loss: 0.747675\n",
      "Epoch 396:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001266\n",
      "Test Error. Accuracy: 83.3%, Avg loss: 0.695858\n",
      "Epoch 397:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.003260\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.490607\n",
      "Epoch 398:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.001051\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.457302\n",
      "Epoch 399:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000469\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.499285\n",
      "Epoch 400:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000593\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.458571\n",
      "Epoch 401:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000475\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.517914\n",
      "Epoch 402:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000633\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.456983\n",
      "Epoch 403:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000449\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.410042\n",
      "Epoch 404:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000232\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.397363\n",
      "Epoch 405:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000208\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.427857\n",
      "Epoch 406:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000675\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.428767\n",
      "Epoch 407:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000249\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.432728\n",
      "Epoch 408:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000296\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.402513\n",
      "Epoch 409:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000156\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.434400\n",
      "Epoch 410:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000174\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.439109\n",
      "Epoch 411:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000348\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.380745\n",
      "Epoch 412:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000369\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.356231\n",
      "Epoch 413:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000331\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.349505\n",
      "Epoch 414:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000100\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.365786\n",
      "Epoch 415:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000174\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.369421\n",
      "Epoch 416:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000133\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.354405\n",
      "Epoch 417:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000121\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.371936\n",
      "Epoch 418:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000420\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.367321\n",
      "Epoch 419:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000187\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.371746\n",
      "Epoch 420:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000119\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.349534\n",
      "Epoch 421:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000125\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.423612\n",
      "Epoch 422:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000053\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.436145\n",
      "Epoch 423:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000155\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.290130\n",
      "Epoch 424:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000039\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.318111\n",
      "Epoch 425:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000060\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.337777\n",
      "Epoch 426:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000153\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.332181\n",
      "Epoch 427:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000042\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.337772\n",
      "Epoch 428:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000059\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.339480\n",
      "Epoch 429:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000101\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.333305\n",
      "Epoch 430:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000079\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.359322\n",
      "Epoch 431:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000125\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.351472\n",
      "Epoch 432:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000049\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.317622\n",
      "Epoch 433:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000041\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.369089\n",
      "Epoch 434:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000071\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.353707\n",
      "Epoch 435:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000075\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.294167\n",
      "Epoch 436:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000034\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.298921\n",
      "Epoch 437:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000039\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.331685\n",
      "Epoch 438:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000033\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.283553\n",
      "Epoch 439:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000052\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.337064\n",
      "Epoch 440:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000018\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.281411\n",
      "Epoch 441:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000031\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.328413\n",
      "Epoch 442:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000028\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.317980\n",
      "Epoch 443:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000030\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.324615\n",
      "Epoch 444:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000024\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.306405\n",
      "Epoch 445:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000028\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.309744\n",
      "Epoch 446:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000017\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.310634\n",
      "Epoch 447:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000019\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.321792\n",
      "Epoch 448:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000011\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.316038\n",
      "Epoch 449:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000024\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.258097\n",
      "Epoch 450:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000033\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.229621\n",
      "Epoch 451:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000017\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.227536\n",
      "Epoch 452:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000025\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.248112\n",
      "Epoch 453:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000014\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.263513\n",
      "Epoch 454:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000010\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.267904\n",
      "Epoch 455:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000053\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.257793\n",
      "Epoch 456:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000011\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.231081\n",
      "Epoch 457:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000004\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.197792\n",
      "Epoch 458:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000018\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.246299\n",
      "Epoch 459:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000008\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.270903\n",
      "Epoch 460:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000008\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.270698\n",
      "Epoch 461:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000013\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.256552\n",
      "Epoch 462:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000038\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.118205\n",
      "Epoch 463:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000026\n",
      "Test Error. Accuracy: 100.0%, Avg loss: 0.072170\n",
      "Epoch 464:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000027\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.099760\n",
      "Epoch 465:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000050\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.165008\n",
      "Epoch 466:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000009\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.275806\n",
      "Epoch 467:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000004\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.259601\n",
      "Epoch 468:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000006\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.304257\n",
      "Epoch 469:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000009\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.243857\n",
      "Epoch 470:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000008\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.164824\n",
      "Epoch 471:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000011\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.161616\n",
      "Epoch 472:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000009\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.179886\n",
      "Epoch 473:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000016\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.175950\n",
      "Epoch 474:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000004\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.191096\n",
      "Epoch 475:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000005\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.164060\n",
      "Epoch 476:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000003\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.184716\n",
      "Epoch 477:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000010\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.179453\n",
      "Epoch 478:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000006\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.171052\n",
      "Epoch 479:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000005\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.163649\n",
      "Epoch 480:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000005\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.164076\n",
      "Epoch 481:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.147012\n",
      "Epoch 482:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000003\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.128392\n",
      "Epoch 483:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000001\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.150189\n",
      "Epoch 484:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.169825\n",
      "Epoch 485:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000001\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.269225\n",
      "Epoch 486:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.178481\n",
      "Epoch 487:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000001\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.186306\n",
      "Epoch 488:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000004\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.132564\n",
      "Epoch 489:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 95.8%, Avg loss: 0.144215\n",
      "Epoch 490:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000005\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.203247\n",
      "Epoch 491:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000001\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.250272\n",
      "Epoch 492:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000001\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.279049\n",
      "Epoch 493:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000000\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.321880\n",
      "Epoch 494:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000003\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.187910\n",
      "Epoch 495:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.251074\n",
      "Epoch 496:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.174604\n",
      "Epoch 497:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000005\n",
      "Test Error. Accuracy: 91.7%, Avg loss: 0.257510\n",
      "Epoch 498:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.227042\n",
      "Epoch 499:\n",
      "Train Error. Accuracy: 100.0%, Avg loss: 0.000002\n",
      "Test Error. Accuracy: 87.5%, Avg loss: 0.281232\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "for t in range(epochs):\n",
    "    train_loss, train_acc = train(trainloader, model, loss_fn, optimizer)\n",
    "    test_loss, test_acc = test(testloader, model, loss_fn)\n",
    "    if t%1 == 0:\n",
    "        print(f\"Epoch {t}:\")\n",
    "        print(f\"Train Error. Accuracy: {(100*train_acc):>0.1f}%, Avg loss: {train_loss:>8f}\")\n",
    "        print(f\"Test Error. Accuracy: {(100*test_acc):>0.1f}%, Avg loss: {test_loss:>8f}\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model can now be used to make predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m cols, rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m2\u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 12\u001b[0m     preds \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[0;32m     13\u001b[0m correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(preds)):\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\resnet.py:285\u001b[0m, in \u001b[0;36mResNet.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 285\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_impl(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\resnet.py:268\u001b[0m, in \u001b[0;36mResNet._forward_impl\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_forward_impl\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    267\u001b[0m     \u001b[38;5;66;03m# See note [TorchScript super()]\u001b[39;00m\n\u001b[1;32m--> 268\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)\n\u001b[0;32m    269\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbn1(x)\n\u001b[0;32m    270\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_conv_forward(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbias)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\u001b[38;5;28minput\u001b[39m, weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    457\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Input type (torch.FloatTensor) and weight type (torch.cuda.FloatTensor) should be the same or input should be a MKLDNN tensor and weight is a dense tensor"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 800x600 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "from torchvision.transforms import ToPILImage\n",
    "\n",
    "\n",
    "classes = [\"bird\", \"cat\", \"dog\"]\n",
    "model.eval()\n",
    "x, labels = next(iter(testloader))\n",
    "\n",
    "figure = plt.figure(figsize=(8, 6))\n",
    "cols, rows = 3, 2\n",
    "with torch.no_grad():\n",
    "    preds = model(x)\n",
    "correct = 0\n",
    "for i in range(len(preds)):\n",
    "    predicted, actual = classes[preds[i].argmax()], classes[labels[i]]\n",
    "    if predicted == actual:\n",
    "        correct += 1\n",
    "    img = x[i]\n",
    "    \"\"\"\n",
    "    mean = torch.tensor([0.485, 0.456, 0.406]).reshape((3,1,1))\n",
    "    std = torch.tensor([0.229, 0.224, 0.225]).reshape((3,1,1))\n",
    "    img = std * img + mean\"\"\"\n",
    "    \n",
    "    figure.add_subplot(rows, cols, i + 1)\n",
    "    plt.title(f\"Actual: {actual}, Pred: {predicted}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(ToPILImage()(img))\n",
    "print(f\"accuracy: %i/%i.\"% ( correct,  len(preds)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Models\n",
    "-------------\n",
    "A common way to save a model is to serialize the internal state dictionary (containing the model parameters).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pth\")\n",
    "print(\"Saved PyTorch Model State to model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Models\n",
    "----------------------------\n",
    "\n",
    "The process for loading a model includes re-creating the model structure and loading\n",
    "the state dictionary into it.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
