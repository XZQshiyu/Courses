{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From a NumPy array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_data.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**From another tensor:**\n",
    "\n",
    "The new tensor retains the properties (shape, datatype) of the argument tensor, unless explicitly overridden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Shape: torch.Size([2, 2])\n",
      "Datatype: torch.int64\n",
      "Random Tensor: \n",
      " tensor([[0.0198, 0.8736],\n",
      "        [0.4010, 0.1167]]) \n",
      "\n",
      "Shape: torch.Size([2, 2])\n",
      "Datatype: torch.float32\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "print(f\"Shape: {x_ones.shape}\")\n",
    "print(f\"Datatype: {x_ones.dtype}\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")\n",
    "print(f\"Shape: {x_rand.shape}\")\n",
    "print(f\"Datatype: {x_rand.dtype}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**With random or constant values:**\n",
    "\n",
    "``shape`` is a tuple of tensor dimensions. In the functions below, it determines the dimensionality of the output tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.1507, 0.0038, 0.5435],\n",
      "        [0.4573, 0.1021, 0.0184]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes of a Tensor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n",
      "numpy: [[0.12863088 0.28437078 0.508887   0.00617874]\n",
      " [0.11320645 0.6388707  0.5424011  0.93210065]\n",
      " [0.09244335 0.47709614 0.02761596 0.67227226]]\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")\n",
    "\n",
    "n = tensor.numpy()\n",
    "print(f\"numpy: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Operations on Tensors\n",
    "~~~~~~~~~~~~~~~~~\n",
    "\n",
    "By default, tensors are created on the CPU. We need to explicitly move tensors to the GPU using\n",
    "``.to`` method (after checking for GPU availability). Keep in mind that copying large tensors\n",
    "across devices can be expensive in terms of time and memory!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We move our tensor to the GPU if available\n",
    "if torch.cuda.is_available():\n",
    "    tensor = tensor.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Standard numpy-like indexing and slicing:**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stack: Concatenates sequence of tensors along a new dimension.\n",
    "\n",
    "cat: Concatenates sequence of tensors along  the given dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 12])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
       "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor, tensor, tensor], dim=1)\n",
    "print(t1.shape)\n",
    "t1\n",
    "# (d1, d2, ..., dn)->(d1, 3*d2, ..., dn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 4])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]],\n",
       "\n",
       "        [[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]],\n",
       "\n",
       "        [[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]],\n",
       "\n",
       "        [[1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.],\n",
       "         [1., 0., 1., 1.]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t2 = torch.stack([tensor, tensor, tensor], dim=1)\n",
    "print(t2.shape)\n",
    "t2\n",
    "# (d1, d2, ..., dn)->(d1, 3, d2, ..., dn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Arithmetic operations**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0990, 0.6141, 0.7851,  ..., 0.2695, 0.6367, 0.7237],\n",
      "        [0.1292, 0.2030, 0.4658,  ..., 0.7093, 0.4272, 0.0343],\n",
      "        [0.6592, 0.0796, 0.9920,  ..., 0.9543, 0.0247, 0.5575],\n",
      "        ...,\n",
      "        [0.9674, 0.6204, 0.7153,  ..., 0.2719, 0.7288, 0.3797],\n",
      "        [0.6176, 0.4246, 0.7363,  ..., 0.4042, 0.9919, 0.7624],\n",
      "        [0.8900, 0.5922, 0.6244,  ..., 0.7449, 0.1976, 0.0030]],\n",
      "       device='cuda:0')\n",
      "0.02245839999523014\n",
      "0.00360319996252656\n",
      "0.0016382000176236033\n",
      "tensor([[0.1980, 1.2281, 1.5702,  ..., 0.5390, 1.2734, 1.4475],\n",
      "        [0.2585, 0.4059, 0.9315,  ..., 1.4187, 0.8544, 0.0686],\n",
      "        [1.3184, 0.1592, 1.9841,  ..., 1.9087, 0.0494, 1.1151],\n",
      "        ...,\n",
      "        [1.9347, 1.2407, 1.4307,  ..., 0.5437, 1.4575, 0.7593],\n",
      "        [1.2352, 0.8491, 1.4726,  ..., 0.8084, 1.9838, 1.5248],\n",
      "        [1.7801, 1.1843, 1.2488,  ..., 1.4898, 0.3953, 0.0061]],\n",
      "       device='cuda:0')\n",
      "tensor([[0.1980, 1.2281, 1.5702,  ..., 0.5390, 1.2734, 1.4475],\n",
      "        [0.2585, 0.4059, 0.9315,  ..., 1.4187, 0.8544, 0.0686],\n",
      "        [1.3184, 0.1592, 1.9841,  ..., 1.9087, 0.0494, 1.1151],\n",
      "        ...,\n",
      "        [1.9347, 1.2407, 1.4307,  ..., 0.5437, 1.4575, 0.7593],\n",
      "        [1.2352, 0.8491, 1.4726,  ..., 0.8084, 1.9838, 1.5248],\n",
      "        [1.7801, 1.1843, 1.2488,  ..., 1.4898, 0.3953, 0.0061]],\n",
      "       device='cuda:0')\n",
      "tensor([[0.1980, 1.2281, 1.5702,  ..., 0.5390, 1.2734, 1.4475],\n",
      "        [0.2585, 0.4059, 0.9315,  ..., 1.4187, 0.8544, 0.0686],\n",
      "        [1.3184, 0.1592, 1.9841,  ..., 1.9087, 0.0494, 1.1151],\n",
      "        ...,\n",
      "        [1.9347, 1.2407, 1.4307,  ..., 0.5437, 1.4575, 0.7593],\n",
      "        [1.2352, 0.8491, 1.4726,  ..., 0.8084, 1.9838, 1.5248],\n",
      "        [1.7801, 1.1843, 1.2488,  ..., 1.4898, 0.3953, 0.0061]],\n",
      "       device='cuda:0')\n",
      "0.0013926000101491809\n",
      "5.280005279928446e-05\n",
      "5.200004670768976e-05\n",
      "tensor([[9.8039e-03, 3.7708e-01, 6.1634e-01,  ..., 7.2637e-02, 4.0540e-01,\n",
      "         5.2379e-01],\n",
      "        [1.6700e-02, 4.1197e-02, 2.1693e-01,  ..., 5.0316e-01, 1.8250e-01,\n",
      "         1.1755e-03],\n",
      "        [4.3455e-01, 6.3360e-03, 9.8412e-01,  ..., 9.1074e-01, 6.1043e-04,\n",
      "         3.1084e-01],\n",
      "        ...,\n",
      "        [9.3581e-01, 3.8485e-01, 5.1172e-01,  ..., 7.3913e-02, 5.3111e-01,\n",
      "         1.4414e-01],\n",
      "        [3.8143e-01, 1.8026e-01, 5.4214e-01,  ..., 1.6337e-01, 9.8382e-01,\n",
      "         5.8127e-01],\n",
      "        [7.9216e-01, 3.5065e-01, 3.8985e-01,  ..., 5.5490e-01, 3.9061e-02,\n",
      "         9.1907e-06]], device='cuda:0')\n",
      "tensor([[9.8039e-03, 3.7708e-01, 6.1634e-01,  ..., 7.2637e-02, 4.0540e-01,\n",
      "         5.2379e-01],\n",
      "        [1.6700e-02, 4.1197e-02, 2.1693e-01,  ..., 5.0316e-01, 1.8250e-01,\n",
      "         1.1755e-03],\n",
      "        [4.3455e-01, 6.3360e-03, 9.8412e-01,  ..., 9.1074e-01, 6.1043e-04,\n",
      "         3.1084e-01],\n",
      "        ...,\n",
      "        [9.3581e-01, 3.8485e-01, 5.1172e-01,  ..., 7.3913e-02, 5.3111e-01,\n",
      "         1.4414e-01],\n",
      "        [3.8143e-01, 1.8026e-01, 5.4214e-01,  ..., 1.6337e-01, 9.8382e-01,\n",
      "         5.8127e-01],\n",
      "        [7.9216e-01, 3.5065e-01, 3.8985e-01,  ..., 5.5490e-01, 3.9061e-02,\n",
      "         9.1907e-06]], device='cuda:0')\n",
      "tensor([[9.8039e-03, 3.7708e-01, 6.1634e-01,  ..., 7.2637e-02, 4.0540e-01,\n",
      "         5.2379e-01],\n",
      "        [1.6700e-02, 4.1197e-02, 2.1693e-01,  ..., 5.0316e-01, 1.8250e-01,\n",
      "         1.1755e-03],\n",
      "        [4.3455e-01, 6.3360e-03, 9.8412e-01,  ..., 9.1074e-01, 6.1043e-04,\n",
      "         3.1084e-01],\n",
      "        ...,\n",
      "        [9.3581e-01, 3.8485e-01, 5.1172e-01,  ..., 7.3913e-02, 5.3111e-01,\n",
      "         1.4414e-01],\n",
      "        [3.8143e-01, 1.8026e-01, 5.4214e-01,  ..., 1.6337e-01, 9.8382e-01,\n",
      "         5.8127e-01],\n",
      "        [7.9216e-01, 3.5065e-01, 3.8985e-01,  ..., 5.5490e-01, 3.9061e-02,\n",
      "         9.1907e-06]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "tensor = torch.tensor([[1,2,3], [1,2,3]])\n",
    "tensor = torch.rand(8192*2, 8192*2).to(\"cuda\")\n",
    "print(tensor)\n",
    "# This computes the element-wise addition.\n",
    "begin_1 = time.perf_counter()\n",
    "z1 = tensor + tensor\n",
    "end_1 = time.perf_counter()\n",
    "print(end_1-begin_1)\n",
    "begin_2 = time.perf_counter()\n",
    "z2 = tensor.add(tensor)\n",
    "end_2 = time.perf_counter()\n",
    "print(end_2-begin_2)\n",
    "begin_3 = time.perf_counter()\n",
    "z3 = torch.add(tensor, tensor)\n",
    "end_3 = time.perf_counter()\n",
    "print(end_3-begin_3)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)\n",
    "\n",
    "\n",
    "# This computes the element-wise product.\n",
    "begin_4 = time.perf_counter()\n",
    "z1 = tensor * tensor\n",
    "end_4 = time.perf_counter()\n",
    "print(end_4-begin_4)\n",
    "begin_5 = time.perf_counter()\n",
    "z2 = tensor.mul(tensor)\n",
    "end_5 = time.perf_counter()\n",
    "print(end_5-begin_5)\n",
    "begin_6 = time.perf_counter()\n",
    "z3 = torch.mul(tensor, tensor)\n",
    "end_6 = time.perf_counter()\n",
    "print(end_6-begin_6)\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)\n",
    "#tensor * scalar  tensor.mul(scalar) torch.mul(tensor, scalar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.11485539993736893\n",
      "2.9041872000088915\n",
      "0.004579100059345365\n",
      "0.017843300011008978\n",
      "tensor([[11000.6094,  8158.0933,  8165.8862,  ...,  8204.7305,  8217.9697,\n",
      "          8246.9697],\n",
      "        [ 8158.0933, 10813.4033,  8097.5659,  ...,  8140.2598,  8182.1450,\n",
      "          8152.4229],\n",
      "        [ 8165.8862,  8097.5659, 10844.0205,  ...,  8144.2036,  8196.2178,\n",
      "          8208.1670],\n",
      "        ...,\n",
      "        [ 8204.7305,  8140.2598,  8144.2036,  ..., 10905.6338,  8195.4648,\n",
      "          8220.3730],\n",
      "        [ 8217.9697,  8182.1450,  8196.2178,  ...,  8195.4648, 10951.3008,\n",
      "          8214.2314],\n",
      "        [ 8246.9697,  8152.4229,  8208.1670,  ...,  8220.3730,  8214.2314,\n",
      "         10987.4551]], device='cuda:0')\n",
      "tensor([[11000.6094,  8158.0933,  8165.8862,  ...,  8204.7305,  8217.9697,\n",
      "          8246.9697],\n",
      "        [ 8158.0933, 10813.4033,  8097.5659,  ...,  8140.2598,  8182.1450,\n",
      "          8152.4229],\n",
      "        [ 8165.8862,  8097.5659, 10844.0205,  ...,  8144.2036,  8196.2178,\n",
      "          8208.1670],\n",
      "        ...,\n",
      "        [ 8204.7305,  8140.2598,  8144.2036,  ..., 10905.6338,  8195.4648,\n",
      "          8220.3730],\n",
      "        [ 8217.9697,  8182.1450,  8196.2178,  ...,  8195.4648, 10951.3008,\n",
      "          8214.2314],\n",
      "        [ 8246.9697,  8152.4229,  8208.1670,  ...,  8220.3730,  8214.2314,\n",
      "         10987.4551]], device='cuda:0')\n",
      "tensor([[11000.6094,  8158.0933,  8165.8862,  ...,  8204.7305,  8217.9697,\n",
      "          8246.9697],\n",
      "        [ 8158.0933, 10813.4033,  8097.5659,  ...,  8140.2598,  8182.1450,\n",
      "          8152.4229],\n",
      "        [ 8165.8862,  8097.5659, 10844.0205,  ...,  8144.2036,  8196.2178,\n",
      "          8208.1670],\n",
      "        ...,\n",
      "        [ 8204.7305,  8140.2598,  8144.2036,  ..., 10905.6338,  8195.4648,\n",
      "          8220.3730],\n",
      "        [ 8217.9697,  8182.1450,  8196.2178,  ...,  8195.4648, 10951.3008,\n",
      "          8214.2314],\n",
      "        [ 8246.9697,  8152.4229,  8208.1670,  ...,  8220.3730,  8214.2314,\n",
      "         10987.4551]], device='cuda:0')\n",
      "tensor([[11000.6094,  8158.0933,  8165.8862,  ...,  8204.7305,  8217.9697,\n",
      "          8246.9697],\n",
      "        [ 8158.0933, 10813.4033,  8097.5659,  ...,  8140.2598,  8182.1450,\n",
      "          8152.4229],\n",
      "        [ 8165.8862,  8097.5659, 10844.0205,  ...,  8144.2036,  8196.2178,\n",
      "          8208.1670],\n",
      "        ...,\n",
      "        [ 8204.7305,  8140.2598,  8144.2036,  ..., 10905.6338,  8195.4648,\n",
      "          8220.3730],\n",
      "        [ 8217.9697,  8182.1450,  8196.2178,  ...,  8195.4648, 10951.3008,\n",
      "          8214.2314],\n",
      "        [ 8246.9697,  8152.4229,  8208.1670,  ...,  8220.3730,  8214.2314,\n",
      "         10987.4551]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([[1,2,3], [1,2,3]])\n",
    "tensor = torch.rand(8192*4, 8192*4).to(\"cuda\")\n",
    "# This computes the matrix multiplication between two tensors.\n",
    "begin_7 = time.perf_counter()\n",
    "y1 = tensor @ tensor.T\n",
    "end_7 = time.perf_counter()\n",
    "print(end_7-begin_7)\n",
    "begin_8 = time.perf_counter()\n",
    "y2 = tensor.matmul(tensor.T)\n",
    "end_8 = time.perf_counter()\n",
    "print(end_8-begin_8)\n",
    "begin_9 = time.perf_counter()\n",
    "y3 = torch.matmul(tensor, tensor.T)\n",
    "end_9 = time.perf_counter()\n",
    "print(end_9-begin_9)\n",
    "begin_10 = time.perf_counter()\n",
    "y4 = torch.mm(tensor, tensor.T)\n",
    "end_10 = time.perf_counter()\n",
    "print(end_10-begin_10)\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)\n",
    "print(y4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 'out' argument can be used to put the result into a exising tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4264, 0.0070, 0.1733,  ..., 0.9625, 0.1178, 0.7814],\n",
      "        [0.2959, 0.3511, 0.9888,  ..., 0.6785, 0.0268, 0.2571],\n",
      "        [0.6725, 0.1353, 0.7236,  ..., 0.6991, 0.9251, 0.2334],\n",
      "        ...,\n",
      "        [0.7741, 0.7595, 0.3189,  ..., 0.2400, 0.3351, 0.4530],\n",
      "        [0.1178, 0.8468, 0.7940,  ..., 0.4842, 0.9984, 0.5704],\n",
      "        [0.1927, 0.3054, 0.7184,  ..., 0.1116, 0.4114, 0.3085]],\n",
      "       device='cuda:0') \n",
      "\n",
      "tensor([[5.4264, 5.0070, 5.1733,  ..., 5.9625, 5.1178, 5.7814],\n",
      "        [5.2959, 5.3511, 5.9888,  ..., 5.6785, 5.0268, 5.2571],\n",
      "        [5.6725, 5.1353, 5.7236,  ..., 5.6991, 5.9251, 5.2334],\n",
      "        ...,\n",
      "        [5.7741, 5.7595, 5.3189,  ..., 5.2400, 5.3351, 5.4530],\n",
      "        [5.1178, 5.8468, 5.7940,  ..., 5.4842, 5.9984, 5.5704],\n",
      "        [5.1927, 5.3054, 5.7184,  ..., 5.1116, 5.4114, 5.3085]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(f\"{tensor} \\n\")\n",
    "torch.add(tensor, 5, out=tensor)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use item() to get the raw value from a pytorch tensor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0001778000732883811\n",
      "tensor(5.9056e+09, device='cuda:0')\n",
      "5905594368.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "begin_11 = time.perf_counter()\n",
    "agg = tensor.sum()\n",
    "end_11 = time.perf_counter()\n",
    "print(end_11-begin_11)\n",
    "print(agg)\n",
    "torch.sum(tensor, dim=1)\n",
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatic Differentiation\n",
    "To compute those gradients, PyTorch has a built-in differentiation engine called torch.autograd. It supports automatic computation of gradient for any computational graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1.])  # input tensor\n",
    "y = torch.tensor([2.])  # expected output\n",
    "w = torch.tensor([1.], requires_grad=True)\n",
    "b = torch.tensor([0.], requires_grad=True)\n",
    "z = x*w+b\n",
    "#loss = torch.square(z - y).sum() \n",
    "loss = torch.pow(z - y, 2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute those derivatives, we call\n",
    "``loss.backward()``, and then retrieve the values from ``w.grad`` and\n",
    "``b.grad`` to get the derivatives $\\frac{\\partial loss}{\\partial w}$ and\n",
    "$\\frac{\\partial loss}{\\partial b}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()\n",
    "print(w.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
